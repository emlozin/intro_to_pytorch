{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "th {\n",
    "  font-size: 24px\n",
    "}\n",
    "td {\n",
    "  font-size: 16px\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to tensors\n",
    "\n",
    "Free after  https://www.manning.com/books/deep-learning-with-pytorch\n",
    "\n",
    "## Core concepts of this section\n",
    "\n",
    "1. A `Tensor` is a `View` onto a `Storage`\n",
    "2. `contiguous` memory layout enables fast computations\n",
    "3. `broadcasting`: expand Tensor dimensions as needed\n",
    "\n",
    "\n",
    "## Fundamentals\n",
    "### Contrast to python list\n",
    "\n",
    "<!-- ![](../img/memory.png \"src: \") -->\n",
    "<div align=\"center\">\n",
    "    <img src=\"../img/memory.svg\" width=\"1200px\" alt=\"in pytorch, a tensor refers to numbers in memory that are all next to each other\">\n",
    "</div>\n",
    "\n",
    "    \n",
    "| entity | plain python | pytorch| \n",
    "|:-------|:------------:|:------:|\n",
    "| numbers | **boxed**: objects with reference counting | 32 bit numbers| \n",
    "| lists | sequential (1dim) collections of pointers to python objects | **adjacent entries in memory**: optimized for computational operations | \n",
    "| interpreter | slow list and math operations | fast | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation\n",
    "\n",
    "Default type at instantiation is torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3); print(a, a.dtype)\n",
    "b = torch.zeros((3, 2)).short(); print(b)\n",
    "c = torch.tensor([1.,2.,3.], dtype=torch.double); print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and storages\n",
    "\n",
    "* the `torch.Storage` is where the numbers actually are\n",
    "* A `torch.Tensor` is a view onto a *torch.Storage*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3,4,5,6])\n",
    "b = a.reshape((3,2))\n",
    "assert id(a.storage()) == id(b.storage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* layout of the storage is always *1D*\n",
    "* hence, changing the value in the storage changes the values of all views (i.e. torch.Tensor) that refer to the same storage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size, storage offset, and strides\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../img/tensor.svg\" width=\"1200px\" alt=\"Meaning of size, offset and stride\">\n",
    "</div>\n",
    "\n",
    "* A Tensor is a view on a storage that is defined by its\n",
    "  * **size:** `t.size()` / `t.shape`\n",
    "  * **storage offset:** `t.stoage_offset()`\n",
    "  * **stride:** `t.stride()`\n",
    "* the **stride** informs how many elements in the storage one needs to move to get to the next value in that dimension\n",
    "* to get `t[i,j]`, get `storage_offset + i * stride[0] + j * stride[1]` of storage\n",
    "* this makes some tensor operations very cheap, because a new tensor has the same storage but different values for size, offset and stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3], [4,5,6]])\n",
    "print(f\"a.size: {a.size()}\")\n",
    "print(f\"a.storage_offset: {a.storage_offset()}\")\n",
    "print(f\"a.stride: {a.stride()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[1]\n",
    "print(f\"b.size: {b.size()}\")\n",
    "print(f\"b.storage_offset: {b.storage_offset()}\")\n",
    "print(f\"b.stride: {b.stride()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transposing a tensor\n",
    "\n",
    "* the transpose just swaps entries in size and stride\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../img/transpose.svg\" width=\"1200px\" alt=\"Transpose explained\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contiguous\n",
    "\n",
    "* A tensor whose values are laid out in the storage starting from the right most dimension onward is **contiguous**\n",
    "  * e.g. 2D tensor:\n",
    "    * `t.size() # torch.Size([#rows, #columns])`\n",
    "    * moving along rows (i.e. fix row, go from one column to the next) is equivalent to going through storage one by one\n",
    "* this data locality improves performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3], [4,5,6]])\n",
    "assert a.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.t()\n",
    "assert not b.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b.contiguous()\n",
    "assert c.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric types\n",
    "\n",
    "* `torch.floatXX`: 32: float, 64: double, 16: half\n",
    "* `torch.intXX`: 8, 16, 32, 64\n",
    "* `torch.uint8`: torch.ByteTensor\n",
    "* `torch.Tensor`: equivalent to torch.FloatTensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Create a tensor a from list(range(9)) . Predict then check what the size, offset, and strides are.\n",
    "2. Create a tensor b = a.view(3, 3) . What is the value of b[1,1] ?\n",
    "3. Create a tensor c = b[1:,1:] . Predict then check what the size, offset, and strides are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Broadcasting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "* similar to [numpy indexing](https://numpy.org/devdocs/user/basics.indexing.html), e.g. `points[1:, 0]`: all but first rows, first column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tips and tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise indexing works\n",
    "t = torch.tensor(range(1, 10)).reshape(3, -1)\n",
    "diagonal = t[range(3), range(3)]\n",
    "diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject additional dimensions with indexing\n",
    "\n",
    "t = torch.rand((3, 64, 64))\n",
    "\n",
    "# Index with `None` at second dim to `unsqeeze`.\n",
    "assert t[:, None].shape == torch.Size([3, 1, 64, 64])\n",
    "\n",
    "# Do it multiple times\n",
    "assert t[:, None, : , None].shape == torch.Size([3, 1, 64, 1, 64])\n",
    "\n",
    "# Can also use ellipsis\n",
    "assert t[..., None].shape == torch.Size([3, 64, 64, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boardcasting\n",
    "\n",
    "Look at the examples below and think about why we can multiply two tensors of different shapes and get the result that one would expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1:\n",
    "a = torch.tensor([\n",
    "    3\n",
    "])\n",
    "b = torch.tensor([\n",
    "    1, 2, 3\n",
    "])\n",
    "torch.testing.assert_allclose(a*b, torch.tensor([\n",
    "    3, 6, 9\n",
    "]))\n",
    "\n",
    "# Example 2:\n",
    "a = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4]\n",
    "])\n",
    "b = torch.tensor([\n",
    "    1, 2\n",
    "])\n",
    "torch.testing.assert_allclose(a*b, torch.tensor([\n",
    "    [1, 4],\n",
    "    [3, 8]\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is that PyTorch magically *expands* the shape of the tensors in a smart way such that operations can be performed.\n",
    "&rarr; This is called **broadcasting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is broadcasting done?\n",
    "\n",
    "1. Compare the dimensions of all tensors, starting from the trailing one.\n",
    "2. If dims are the same, do nothing\n",
    "3. If one dim is 1 (or missing), expand it to match the other dim.\n",
    "4. Else: abort\n",
    "\n",
    "**Note:** When broadcasting, PyTorch does not acutally need to expand the dimensions of a tensor in memory in order to perform efficient tensor operations.\n",
    "\n",
    "```\n",
    "Example 1\n",
    "[a]:    3 x 64 x 64\n",
    "[b]:              1\n",
    "[a*b]:  3 x 64 x 64\n",
    "\n",
    "Example 2\n",
    "[a]:    3 x  1 x 64\n",
    "[b]:    1 x 64 x  1\n",
    "[a*b]:  3 x 64 x 64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "4. Indexing: Get the diagonal elements of `t.rand(3, 3)` by reshaping into a 1d tensor and taking every fourth element, starting from the first.\n",
    "5. Broadcasting: Write down the shapes of the tensors in the examples and convince yourself that the output shape is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4:\n",
    "t = torch.rand(3,3)\n",
    "diag_expected = t[range(3), range(3)]\n",
    "\n",
    "diag_actual = ???\n",
    "\n",
    "torch.testing.assert_allclose(diag_actual, diag_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy interoperability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_np = t.numpy()\n",
    "t = torch.from_numpy(t_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialization\n",
    "\n",
    "* use `torch.save(t, \"path_to_file.t\")` and `torch.load(\"path_to_file.t\")`\n",
    "* alternatively, can use in combination with `hdf5` file format (library: h5py)\n",
    "\n",
    "### GPU\n",
    "\n",
    "* pytorch makes it very easy to use one or several GPUs, using the `torch.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device(\"cpu\") # use cpu by default\n",
    "torch.device(\"cuda\") # GPU\n",
    "torch.device(\"cuda:0\") # index multiple GPUs #0 -> default: 0\n",
    "torch.device(\"cuda:1\") # use GPU #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* delegate a tensor to a device using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.to(torch.device(\"cpu\")))\n",
    "print(t.cpu())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(t.cuda())\n",
    "    print(t.cuda(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor API\n",
    "\n",
    "For pytorch, there exists a ton of ops... whatever you would like to do, it's probably already implemented in a performant manner.\n",
    "\n",
    "**Pytorch convention:** a mathemtical operation often has an in-place equivalent referenced by using the suffix `_`. E.g. `t.cos()` and `t.cos_()`\n",
    "\n",
    "Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(range(10), dtype=torch.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.log_(); t # operates in-place/ mutates tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.\n",
    "\n",
    "Caclulate the mean squared error between predictions and target values: $\\rm mse = \\frac{1}{N}\\sum_i^N (p_i - t_i)^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(p, t):\n",
    "    pass\n",
    "\n",
    "x = torch.tensor([0.8878, 0.3297, 0.5110, 0.5384, 0.2123, 0.3426, 0.7011, 0.8208, 0.8864, 0.6434, 0.1740, 0.0737, 0.8329, 0.0571, 0.6244, 0.9390, 0.5501, 0.6998, 0.7668, 0.5981, 0.1187, 0.6488, 0.3909, 0.8849, 0.3510, 0.7472, 0.4878, 0.2781, 0.5326, 0.1480, 0.4136, 0.4267, 0.6989, 0.3887, 0.5068, 0.5511, 0.5643, 0.0901, 0.1359, 0.5701, 0.4774, 0.9935, 0.1502, 0.7608, 0.4538, 0.4217, 0.1825, 0.9382, 0.8646, 0.1383, 0.0363, 0.2364, 0.1937, 0.2695, 0.4807, 0.7768, 0.2784, 0.3547, 0.0922, 0.5994, 0.0868, 0.0460, 0.0812,\n",
    "        0.0319, 0.2429, 0.3504, 0.6014, 0.9268, 0.2222, 0.5592, 0.2112, 0.3517, 0.1994, 0.3877, 0.8518, 0.3747, 0.9385, 0.5225, 0.9855, 0.7657, 0.5585, 0.0929, 0.5815, 0.0804, 0.9209, 0.8802, 0.6289, 0.9143, 0.0038, 0.7857, 0.9591, 0.8305, 0.1844, 0.0162, 0.1324, 0.0526, 0.2213, 0.6377, 0.6446, 0.6945])\n",
    "y = torch.tensor([0.2142, 0.7458, 0.7008, 0.2043, 0.1460, 0.2145, 0.7116, 0.6624, 0.8765, 0.2938, 0.4653, 0.1229, 0.8056, 0.2956, 0.4171, 0.0459, 0.3799, 0.5624, 0.4551, 0.1322, 0.7540, 0.0425, 0.3713, 0.4406, 0.8243, 0.5511, 0.1352, 0.7495, 0.0901, 0.2131, 0.7758, 0.9060, 0.7875, 0.5118, 0.5368, 0.3445, 0.8501, 0.2982, 0.2606, 0.4571, 0.8108, 0.7400, 0.2336, 0.6150, 0.9143,\n",
    "        0.4178, 0.2335, 0.5490, 0.4379, 0.3335, 0.8449, 0.6327, 0.1062, 0.4313, 0.7856, 0.6156, 0.3859, 0.5551, 0.4448, 0.3231, 0.3505, 0.3295, 0.8727, 0.9072, 0.9495, 0.6936, 0.5648, 0.0132, 0.2811, 0.5219, 0.4193, 0.8747, 0.7140, 0.6307, 0.0449, 0.4598, 0.0337, 0.3839, 0.7451, 0.2710, 0.3802, 0.8890, 0.8482, 0.6723, 0.7480, 0.1293, 0.6862, 0.8104, 0.3573, 0.7695, 0.1230, 0.3649, 0.8067, 0.2198, 0.3240, 0.1938, 0.8909, 0.1115, 0.4997, 0.4708])\n",
    "\n",
    "torch.testing.assert_allclose(mse(x, y), 0.16112)\n",
    "torch.testing.assert_allclose(mse(torch.ones(3), torch.ones(3)), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The [Group Normalizatoin Paper](https://arxiv.org/pdf/1803.08494.pdf) shows a nice figure on how different normalization schemes slice a tensor.\n",
    "\n",
    "![Figure](../img/group_norm.png)\n",
    "\n",
    "Choose one scheme and normalize the below tensor accordingly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BATCH_SIZE, C_NUMBER_OF_CHANNELS, H_HEIGHT, W_WIDTH = 32, 3, 64, 64\n",
    "\n",
    "t = torch.rand(N_BATCH_SIZE, C_NUMBER_OF_CHANNELS, H_HEIGHT, W_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto grad\n",
    "\n",
    "Fundamental to optimization is the ability to perform differntiation. PyTorch does this with its **autograd** framework, which we will dive into now.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../img/autograd.svg\" width=\"1200px\" alt=\"Tracking derivatives through the compute graph\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Concepts\n",
    "\n",
    "1. Compute graph and chain rule \n",
    "1. `t.requires_grad_()` and `t.grad`\n",
    "2. `t.backward()`\n",
    "3. `param.detach` and `torch.no_grad()` \n",
    "4. zeroing the gradient\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent by hand...\n",
    "\n",
    "We want to find the minimum of a quadratic function and show how PyTorch can help us to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a quadratic function and plot it\n",
    "\n",
    "def second_order_polynomial(x, a, b, c):\n",
    "    return a*x**2 + b*x + c\n",
    "\n",
    "def show_sop(x, y):\n",
    "    fig, ax = plt.subplots(1, figsize=(7,7))\n",
    "    ax.set_ylabel(\"$y$\", fontsize=20)\n",
    "    ax.set_xlabel(\"$x$\", fontsize=20)\n",
    "    ax.plot(x, y, linewidth=4 )\n",
    "    ax.set_title(\"$ax^2 + bx + c$\", fontsize=24)\n",
    "\n",
    "a, b, c = 0.5, 1.3, 2.8\n",
    "\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "show_sop(x, second_order_polynomial(x, a, b, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know that $\\frac{d}{dx} f(x) = \\frac{d}{dx} ax^2 + bx + c = 2ax + b$.\n",
    "\n",
    "Does PyTorch also know that? Let's see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Dependent variable\n",
    "\n",
    "We first need to let PyTorch know that $x$ is our dependent variable. We do so by specifying that $x$ requires the computation of gradients, using `requires_grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2.5], requires_grad=True)\n",
    "\n",
    "# or \n",
    "x = torch.tensor([2.5])\n",
    "x.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Perform computations with dependent variable \n",
    "\n",
    "Next, we want to compute something with this variable, namely our quadratic function $f(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = second_order_polynomial(x, a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the `requires_grad` attribute, PyTorch dynamically tracks the dependency on `x` on any computation on x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compute the gradients\n",
    "\n",
    "Now we wish to compute the gradients. This is simply done by calling `backward()` on $y$. The gradients can then be found in the `x.grad` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check agreement\n",
    "\n",
    "Let's also check with the expected result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x.grad == 2*a*x + b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Repeat\n",
    "\n",
    "##### **Parameter update**\n",
    "\n",
    "* Notice that we haven't found a value of `x` yet where $f(x)$ is minimum.\n",
    "* But the gradient descent algorithm at least tells us in which direction we should continue our search.\n",
    "* Since the gradient is positive, we know that `f(x)` keeps growing in the postiive x direction. Hence, we should choose a smaller value for x.\n",
    "* However, if we now operate on x in order to reduce its value, we will change the graph of x. To avoid this, we can ask PyTorch to operate on x without tracking this operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x -= 1. # just guessed some value\n",
    "print(x.requires_grad) # still requires grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side note:** It can sometimes be necessary to stop computing gradients altogether. In this case, use `x.detach`:\n",
    "\n",
    "```python\n",
    "some_other_thing = x.detach()\n",
    "assert not some_other_thing.requires_grad\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Zeroing the gradient**\n",
    "\n",
    "Notice that x still has a gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everytime we call `backward` on some `y(x)`, we will accumulate gradients in `x`. This is helpful if for example we want to compute gradients across multiple GPUs...\n",
    "\n",
    "But fow now that is not what we want to do. Instead we want to compute the gradient for a new value of x. So we whould reset `x.grad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Next**\n",
    "Now, let's go back to step 2. And see if we are closer to the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "1. Use `requires_grad` to let PyTorch know your dependent variable.\n",
    "2. Now every operation on `x` is tracked in order to dynamically build the compute graph involving `x`.\n",
    "3. Use `y.backward()` to compute the gradient of `y` using the chain rule. This works because the Tensor framework implements a `forward` and `backward` operation for each computational operation. This includes overloading `a.__mult__(self, b)` etc.\n",
    "4. Make sure to `detach` some operations on `x` form the compute graph if they are not required for the computation of gradients. Use `x.detach` or `torch.no_grad()` \n",
    "5. Each call to `y.backward()` will accumulate gradients in the leaves of the graph. Make sure to zero the gradients after a parameter udpate.\n",
    "\n",
    "These are the essential steps to computing gradients with PyTorch. We will later discover PyTorch's higher-level API that helps us make those steps more user friendly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Least squares fit for a linear function\n",
    "\n",
    "Find the best set of parameters `m, b` for a linear model $f(x) = mx + b$ that best fit the data.\n",
    "\n",
    "To do so, you will have to:\n",
    "1. Decide which are your depndent variables.\n",
    "2. Calculate the mean squared error.\n",
    "3. Caclulate the gradient of the mse with respect to the dependent variables\n",
    "4. Perform a parameter update \n",
    "5. Iterate until some stopping condition.\n",
    "\n",
    "To help you with these task, some functions and the training loop are already set up for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(x, params):\n",
    "    return params[0]*x + params[1]\n",
    "\n",
    "def noise(signal):\n",
    "    n = torch.zeros(signal.shape)\n",
    "    torch.nn.init.normal_(n)\n",
    "    return n\n",
    "\n",
    "def mse(p, t):\n",
    "    return (p - t).pow(2).mean()\n",
    "\n",
    "def show_fit(x, p, t):\n",
    "    fig, ax = plt.subplots(1, figsize=(7,7))\n",
    "    ax.plot(x.numpy(), t.numpy(), marker=\"o\", linewidth=0)\n",
    "    ax.plot(x.numpy(), p.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "initial_parmas = torch.tensor([1., 0.])\n",
    "target_params = torch.tensor([3.4, -0.8])\n",
    "\n",
    "x = torch.tensor(range(10))\n",
    "data = linear_model(x, target_params) + noise(x)\n",
    "\n",
    "assert mse(linear_model(x, initial_parmas), data) > 100\n",
    "\n",
    "show_fit(x, linear_model(x, initial_parmas), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training loop\n",
    "lr = 0.01\n",
    "n_epochs = 10\n",
    "initial_parmas = torch.tensor([1., 0.], requires_grad=True)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # calculate loss\n",
    "    loss = ???\n",
    "    print(f\"Loss at epoch [{epoch}]: [{loss.item()}]\")\n",
    "    \n",
    "    # calculate gradients / propagate error\n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad():\n",
    "        pass\n",
    "    \n",
    "with torch.no_grad():\n",
    "    show_fit(x, linear_model(x, initial_parmas), data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro_to_pytorch",
   "language": "python",
   "name": "intro_to_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
