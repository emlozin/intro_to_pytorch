{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1c. Introduction: Why PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immediate vs deferred execution\n",
    "* usually, the Python interpreter executes eagerly\n",
    "* functions can be used to defer execution\n",
    "* thanks to operator overloading, an expression can look like it will be executed eagerly, but it is deferred\n",
    " \n",
    "```python\n",
    "a = InputParameterPlaceholder()\n",
    "b = InputParameterPlaceholder()\n",
    "c = (a**2 + b**2) ** 0.5 # __add__ and __mul__ are overloaded\n",
    "callable(c) # True # c is some execution graph\n",
    "```\n",
    "\n",
    "* that way\n",
    "    * the computation is not recorded as Python byte code operation\n",
    "    * but instead it is compiled into a static graph that can be converted into optimized (fused) machine code\n",
    "* this has two downsides:\n",
    "    1. cannot use python tools for debugging\n",
    "    2. cannot mix with python flow control (e.g. if statements etc)\n",
    "    \n",
    "### Static vs. dynamic graph\n",
    "* static graph/ deferred execution: builds up the entire computation as a graph\n",
    "* dynamic graph/ eager execution: an operation is not aware of the following operation\n",
    "    * 'define by run' \n",
    "    * dynamic is not better per se, but it's easier to accomplish looping or conditional behavior with dynamic graphs as it integrates better with python control flow\n",
    "* `PyTorch` eager by default, static graph capabilities added by `TorchScript` in order to optimize production builts\n",
    "* `TensorFlow` only static in TF1; since TF2, eager by default\n",
    "\n",
    "## Framework history\n",
    "### TF\n",
    "* TF2 is eager by default\n",
    "* robust pipeline to production\n",
    "* widely used in industry\n",
    "* massive mind share\n",
    "      \n",
    "### PyTorch\n",
    "* consumed Caffe2 backend\n",
    "* replaced low-level code from Lua-based Torch project\n",
    "* support for ONNX\n",
    "* delayed execution graph mode runtime: TorchScript\n",
    "* widely spread in research and education\n",
    "\n",
    "\n",
    "**Overall**, TF and PyTorch are converging\n",
    "\n",
    "# PyTorch has the batteries included\n",
    "* written in C++ and CUDA, can be run from C directly\n",
    "* essential building blocks: \n",
    "    * *Tensor* \n",
    "        * Tensors with *native support for backpropagation*: tensors remember what operations has been executed on them\n",
    "    * additional support due to *torch.autograd*\n",
    "* Makes pytorch attractive for use cases beyond NN: physics, rendering, optimization, simulation, modeling\n",
    "\n",
    "## Modules\n",
    "* for training, one needs to *source data*, *run an optimizer*, *hardware delegation*\n",
    "* `torch.util.data` :: provides \n",
    "    * Dataset :: bridges between custom data and *Tensor*\n",
    "    * Dataloader :: spawns child processes to load data in the background\n",
    "* hardware delegation with help of `torch.nn.DataParallel` and `torch.distributed`\n",
    "* `torch.optim` :: for learning\n",
    "* TorchScript :: delegating computations to C++/ Cuda is efficient but incurs a small overhead cost in the python layer each time\n",
    "    * this can add up if repeated often\n",
    "    * TorchScript enables deferred execution, which serializes an instruction set that can be invoked independently from python\n",
    "    * like a virtual machine with instruction set for tensor operations\n",
    "    * also just-in-time transformation of sequences of known operations into fused operations\n",
    "    \n",
    "## Ecosystem\n",
    "PyTorch is not 'only' a single `torch` library but it offers a lot of additional modules, libraries and tools designed for variety of use cases. Some of the most interesting parts of it include:\n",
    "\n",
    "- [fastai](https://docs.fast.ai/) - \"training fast and accurate neural nets using modern best practices\".\n",
    "- [ParlAI](https://parl.ai/) - \"sharing, training and evaluating dialogue models across many tasks\".\n",
    "- [Ray](https://github.com/ray-project/ray) - \"for building and running distributed applications\".\n",
    "\n",
    "More about PyTorch ecosystem can be found in [PyTorch documentation](https://pytorch.org/ecosystem/).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
