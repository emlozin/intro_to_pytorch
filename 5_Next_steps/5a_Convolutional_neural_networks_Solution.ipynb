{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5a. Convolutional neural networks\n",
    "\n",
    "Traditional multilayered perceptron has many limitations. It does not take spatial structure of data into consideration. Let's not forget about the fact that fully connected layers lead to huge numbers of weights for images with high resolution and therefore make it impossible to process data efficiently. \n",
    "\n",
    "That's where CNNs (convolutional neural networks) come to play. The idea behind it is how visual cortex analyzes images. It creates and adapts filters that extract features. In contrast to classical image classifiers, the filters are not hand-engineered by experts but trained automatically within the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN structure\n",
    "\n",
    "Let's take a look at the one of the built-in CNN model available in `torchvision` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "alexnet = models.alexnet()\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it contains many layers of different types. It may seem complicated at first, but those building blocks will be explained in this section so don't worry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layers\n",
    "\n",
    "It is no surprise that convolutional layers are the core concept used in CNNs. The convolution is an operation that can be seen as applying filters to the images. One of the most popular filters using convolution is Sobel filter detecting edges which you can see below.\n",
    "\n",
    "Convolutional layers 'learn' which filters need to be applied by themselves. There is no need to hand engineer and adapt the filters anymore. The network adapts its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolutional_layer = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=0, stride=1)\n",
    "print(convolutional_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Conv2d?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling layers\n",
    "\n",
    "Using convolutional layers can lead to increasing dimension of the layers. In order to reduce the number of parameters in the network, we use pooling layers. These are the layers which down-sample their inputs by using selected function (eg. maximum value within the frame). This process is presented in the picture below: \n",
    "\n",
    "![pooling layer](image \"Max pooling layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.arange(-8, 8, dtype=np.float32).reshape((1,4,4))\n",
    "input_layer = torch.from_numpy(input_array)\n",
    "\n",
    "pd.DataFrame(data=input_layer.numpy().reshape((4,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max\n",
    "\n",
    "One of the most popular type of pooling layers is max pooling. As its name suggests, it takes the highest value within the frame. In PyTorch there are several ways to use max pooling layer:\n",
    "\n",
    "- `nn.MaxPool2d` - simplest to use, you specify the size of the kernel, stride and padding yourself,\n",
    "- `nn.AdaptiveMaxPool2d` - you specify the size of the output, size of the kernel, other parameters are adapted according to the given parameters,\n",
    "- `nn.FractionalMaxPool2d` - applies fractional max pooling, you specify the size of the kernel and the size of the output/output ratio, described in detail in the paper [Fractional MaxPooling by Ben Graham](https://arxiv.org/abs/1412.6071)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "\n",
    "Declare max pooling layer, pass input layer through it and display results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool = nn.MaxPool2d(2)\n",
    "pd.DataFrame(data=max_pool(input_layer).numpy().reshape((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adp_max_pool = nn.AdaptiveMaxPool2d(output_size=(2,2))\n",
    "pd.DataFrame(data=adp_max_pool(input_layer).numpy().reshape((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_max_pool = nn.FractionalMaxPool2d(2, output_size=(2, 2))\n",
    "pd.DataFrame(data=frac_max_pool(input_layer).numpy().reshape((2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average\n",
    "\n",
    "Another type of pooling layer is average pooling. Again, PyTorch provides several options to use it:\n",
    "\n",
    "- `nn.AvgPool2d` - simplest to use, you specify the size of the kernel, stride and padding yourself,\n",
    "- `nn.AdaptiveAvgPool2d` - you specify the size of the output, size of the kernel, other parameters are adapted according to the given parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "\n",
    "Declare average pooling layer, pass input layer through it and display results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pool = nn.AvgPool2d(2)\n",
    "pd.DataFrame(data=avg_pool(input_layer).numpy().reshape((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adp_avg_pool = nn.AdaptiveAvgPool2d(output_size=(2,2))\n",
    "pd.DataFrame(data=adp_avg_pool(input_layer).numpy().reshape((2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power average\n",
    "\n",
    "The last type of built-in pooling in PyTorch is power average pooling, which calculates the output according to this formula:\n",
    "\n",
    "\\begin{equation}\n",
    "f(X)=\\sqrt[p]{\\sum_{x \\in X}x^p}\n",
    "\\end{equation}\n",
    "\n",
    "If you use $p=1$ you get sum pooling, $p=\\infty $ returns results similar to max pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4:\n",
    "\n",
    "Declare power average pooling layer, pass input layer through it and display results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_pool = nn.LPPool2d(2, 2)\n",
    "pd.DataFrame(data=lp_pool(input_layer).numpy().reshape((2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation layers\n",
    "\n",
    "Another block in CNNs are activation layers which were discussed in [Neural networks notebook](../3_Neural_networks/3a_Neural_network_module.ipynb). If you need to refresh your memory, please refer to the section Activation layers there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5:\n",
    "\n",
    "Declare ReLU activation layer and pass output of the pooling layer of your choice through it. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_layer = nn.ReLU()\n",
    "pd.DataFrame(data=act_layer(adp_avg_pool(input_layer)).numpy().reshape((2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "\n",
    "Classifier is the last part of the network. It is a linear neural network which analyzes features extracted by the previous blocks and provides information about the predicted class. Again, for more about linear networks, please refer to [Neural networks notebook](../3_Neural_networks/3a_Neural_network_module.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6:\n",
    "\n",
    "Declare classifier similar to the one used in AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Sequential(\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(in_features=9216, out_features=4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(in_features=4096, out_features=4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=4096, out_features=1000),\n",
    "  )\n",
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10\n",
    "\n",
    "In this notebook, we will be working with CIFAR10 dataset available in `torchvision`. It provides images of the objects of ten classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workshop import data\n",
    "\n",
    "train_cifar = torchvision.datasets.CIFAR10(data.DATA_PATH, download=True, train=True)\n",
    "test_cifar = torchvision.datasets.CIFAR10(data.DATA_PATH, download=True, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "We discussed the basics of CNNs. Now it's time to implement your first network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # input 32x32x3\n",
    "        self.conv_1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        # input 16x16x16\n",
    "        self.conv_2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # input 8x8x32\n",
    "        self.conv_3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        \n",
    "        # reduces size by 2\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # input 4x4x64\n",
    "        self.lin_1 = nn.Linear(4*4*64, 128)\n",
    "        self.lin_2 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.dropout = nn.Dropout()\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.pool(self.act(self.conv_1(x)))\n",
    "        x = self.pool(self.act(self.conv_2(x)))\n",
    "        x = self.pool(self.act(self.conv_3(x)))\n",
    "        \n",
    "        x = x.flatten()\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.act(self.lin_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.act(self.lin_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [PyTorch NN module documentation](https://pytorch.org/docs/stable/nn.html)\n",
    "- [Convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network)\n",
    "- [Convolutional layers for deep learning neural networks](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro_to_pytorch",
   "language": "python",
   "name": "intro_to_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
