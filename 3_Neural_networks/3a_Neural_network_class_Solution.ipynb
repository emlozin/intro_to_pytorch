{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a. Neural networks with PyTorch using class\n",
    "\n",
    "PyTorch nn module offers building blocks (layers, functions, containers) to build neural networks. These are well presented in [torch.nn documentation](https://pytorch.org/docs/stable/nn.html \"torch.nn module documentation\"). This notebook should give you a good outlook of the module capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Transforms define which steps will be applied to each sample\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5],\n",
    "                         std=[0.5]),\n",
    "])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "\n",
    "Load data and read sizes of training data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images), type(labels))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "\n",
    "Define a network with a following configuration:\n",
    "\n",
    "* one hidden linear layer with sigmoid activation function\n",
    "* one output linear layer with softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TODO: Define hidden layer\n",
    "        self.hidden = nn.Linear(28*28,256)\n",
    "                \n",
    "        # TODO: Define output layer\n",
    "        self.output = nn.Linear(256,10)\n",
    "        \n",
    "        # TODO: Define activation functions\n",
    "        self.hidden_activation = nn.Sigmoid()\n",
    "        self.output_activation = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.hidden_activation(x)\n",
    "        x = self.output(x)\n",
    "        x = self.output_activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "helper.test_network(network, trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "\n",
    "Define a network with an architecture of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TODO: Define all network layers \n",
    "        # Remember to define at least:\n",
    "        # - input to hidden (input size: )\n",
    "        # - hidden to output (output size: 10)\n",
    "        \n",
    "        self.hidden = nn.Linear(28*28,256)\n",
    "        self.output = nn.Linear(256,10)\n",
    "        # TODO: Define all activation functions\n",
    "        # - use softmax for last layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Pass input tensor through all defined layers\n",
    "        \n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = torch.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = torch.softmax(self.output(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()\n",
    "helper.test_network(network, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
